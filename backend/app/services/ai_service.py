# app/services/ai_service.py
"""
üìÑ Fichier: app/services/ai_service.py
üìù Description: Service IA pour recommandations via Groq
"""

from groq import Groq
import os
from typing import Dict, List, Optional
import json
from dotenv import load_dotenv

load_dotenv()

GROQ_API_KEY = os.getenv("GROQ_API_KEY")
if not GROQ_API_KEY:
    raise ValueError("‚ùå GROQ_API_KEY manquante dans .env")

groq_client = Groq(api_key=GROQ_API_KEY)

# ‚úÖ MOD√àLE MIS √Ä JOUR (novembre 2025)
DEFAULT_MODEL = "llama-3.3-70b-versatile"  # Remplace l'ancien llama-3.1-70b
MODEL_RAPIDE = "llama-3.1-8b-instant"      # Pour suggestions courtes

class AIService:
    
    @staticmethod
    async def generer_recommandations_intervention(
        maladie_nom: str,
        district_nom: str,
        nb_cas: int,
        tendance: str,
        cas_recents: List[Dict],
        interventions_passees: Optional[List[Dict]] = None,
        alerte_info: Optional[Dict] = None
    ) -> Dict:
        """
        ü§ñ G√©n√®re 3 recommandations d'interventions via Groq
        """
        
        contexte = f"""Tu es un expert en √©pid√©miologie pour Madagascar (r√©gion Vakinankaratra).

SITUATION ACTUELLE:
- Maladie: {maladie_nom}
- District: {district_nom}
- Nombre de cas: {nb_cas}
- Tendance: {tendance}
"""

        if alerte_info:
            contexte += f"\n- üö® ALERTE: {alerte_info['niveau_gravite']} - {alerte_info['description']}"
        
        if interventions_passees and len(interventions_passees) > 0:
            contexte += f"\n\nINTERVENTIONS R√âCENTES:"
            for interv in interventions_passees[:3]:
                contexte += f"\n- {interv['type']}: {interv['titre']} (Efficacit√©: {interv.get('efficacite_score', 'N/A')}/5)"

        prompt = f"""{contexte}

Recommande 3 interventions prioritaires. Format JSON exact:

{{
  "interventions": [
    {{
      "titre": "Titre clair et court (max 60 caract√®res)",
      "description": "Description d√©taill√©e en 3-4 phrases",
      "type": "vaccination|sensibilisation|desinfection|distribution_medicaments|formation_personnel|enquete_terrain|autre",
      "priorite": 1|2|3,
      "justification": "Pourquoi cette intervention maintenant?",
      "population_cible": nombre_estim√©,
      "budget_estime": montant_en_ariary,
      "duree_jours": nombre_de_jours,
      "ressources": ["ressource1", "ressource2", "ressource3"],
      "indicateurs_succes": ["indicateur1", "indicateur2"]
    }}
  ],
  "analyse_globale": "Synth√®se √©pid√©miologique (2-3 phrases)",
  "risques_identifies": ["risque1", "risque2", "risque3"],
  "recommandations_generales": "Conseils additionnels"
}}

Types valides: vaccination, sensibilisation, desinfection, distribution_medicaments, formation_personnel, enquete_terrain, autre
R√©ponds UNIQUEMENT en JSON pur, sans markdown."""

        try:
            completion = groq_client.chat.completions.create(
                messages=[
                    {
                        "role": "system",
                        "content": "Expert sant√© publique Madagascar. R√©ponses JSON structur√©es, pr√©cises et actionnables."
                    },
                    {
                        "role": "user",
                        "content": prompt
                    }
                ],
                model=DEFAULT_MODEL,  # ‚úÖ Utilise le nouveau mod√®le
                temperature=0.3,
                max_tokens=2500,
                response_format={"type": "json_object"}
            )
            
            response_text = completion.choices[0].message.content
            recommendations = json.loads(response_text)
            
            return {
                "success": True,
                "data": recommendations,
                "model": DEFAULT_MODEL,
                "tokens": completion.usage.total_tokens
            }
            
        except Exception as e:
            print(f"‚ùå Erreur Groq: {str(e)}")
            return {
                "success": False,
                "error": str(e),
                "data": AIService._fallback_recommendations(maladie_nom, nb_cas)
            }
    
    @staticmethod
    def _fallback_recommendations(maladie: str, nb_cas: int) -> Dict:
        """Recommandations de secours si Groq √©choue"""
        return {
            "interventions": [
                {
                    "titre": f"Investigation {maladie}",
                    "description": f"Enqu√™te √©pid√©miologique sur les {nb_cas} cas d√©clar√©s",
                    "type": "enquete_terrain",
                    "priorite": 1,
                    "justification": "Investigation standard obligatoire",
                    "population_cible": nb_cas * 10,
                    "budget_estime": 500000,
                    "duree_jours": 7,
                    "ressources": ["√âquipe mobile", "Kits pr√©l√®vement"],
                    "indicateurs_succes": ["Tous cas investigu√©s", "Source identifi√©e"]
                }
            ],
            "analyse_globale": "Recommandations standard appliqu√©es (IA indisponible)",
            "risques_identifies": ["Propagation communautaire"],
            "recommandations_generales": "Suivre protocoles Minist√®re Sant√© Publique"
        }
    
    @staticmethod
    async def suggerer_action_alerte(
        alerte: Dict,
        nb_cas: int,
        interventions_en_cours: int
    ) -> str:
        """
        ü§ñ Suggestion d'action courte pour une alerte (affichage UI)
        """
        
        prompt = f"""Situation d'alerte √©pid√©miologique √† Madagascar:
- Maladie: {alerte['maladie_nom']}
- District: {alerte['district_nom']}
- Niveau: {alerte['niveau_gravite']}
- Cas: {nb_cas}
- Interventions actives: {interventions_en_cours}

Fournis UNE action prioritaire imm√©diate en 1 phrase courte (max 120 caract√®res).
Format: "Action: [description]"
"""

        try:
            completion = groq_client.chat.completions.create(
                messages=[
                    {"role": "system", "content": "Expert sant√© publique. R√©ponses ultra-concises."},
                    {"role": "user", "content": prompt}
                ],
                model=MODEL_RAPIDE,  # ‚úÖ Utilise le mod√®le rapide
                temperature=0.2,
                max_tokens=80
            )
            
            return completion.choices[0].message.content.strip()
            
        except Exception as e:
            return f"Action: Investiguer imm√©diatement les {nb_cas} cas dans {alerte['district_nom']}"
